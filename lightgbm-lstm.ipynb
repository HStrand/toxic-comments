{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained = \"data\\\\crawl-300d-2M.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector = get_pretrained(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data\\\\train.csv\").fillna(' ')\n",
    "test = pd.read_csv(\"data\\\\test.csv\").fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "def tokenize(row):\n",
    "    return re_tok.sub(r' \\1 ', row).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train['comment_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test['comment_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nlp_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [column for column in train.columns[2:8]]\n",
    "feature_funcs = [len, asterix_freq, uppercase_freq, line_change_freq, rep_freq, question_freq]\n",
    "transforms = [tokenize]\n",
    "logreg = LogisticRegression(C=0.2, class_weight='balanced', solver='newton-cg', max_iter=10)\n",
    "logreg.name = \"Logistic regression newton\"\n",
    "models = [logreg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (159571, 8)\n",
      "Test: (153164, 2)\n",
      "Train features: (0,)\n",
      "Test features: (0,)\n",
      "Input column: comment_text\n",
      "Class labels: toxic severe_toxic obscene threat insult identity_hate\n",
      "Models: Logistic regression newton: 0.2 balanced False True 1 10 ovr 1 l2 None newton-cg 0.0001 0 False | \n",
      "Transforms:  tokenize\n",
      "Feature functions:  function asterix_freq uppercase_freq line_change_freq rep_freq question_freq\n",
      "Metric: roc_auc\n",
      "CV scores: {'Logistic regression newton': -1}\n"
     ]
    }
   ],
   "source": [
    "pipe = NlpPipeline(train, test, \"comment_text\", class_labels, feature_funcs, transforms, models, word_vectors=word_vector, pretrained=pretrained)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train: (159571, 8)\n",
       "Test: (153164, 2)\n",
       "Train features: (159571, 6)\n",
       "Test features: (153164, 6)\n",
       "Input column: comment_text\n",
       "Class labels: toxic severe_toxic obscene threat insult identity_hate\n",
       "Models: Logistic regression newton: 0.2 balanced False True 1 10 ovr 1 l2 None newton-cg 0.0001 0 False | \n",
       "Transforms:  tokenize\n",
       "Feature functions:  function asterix_freq uppercase_freq line_change_freq rep_freq question_freq\n",
       "Metric: roc_auc\n",
       "CV scores: {'Logistic regression newton': -1}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transforms\n"
     ]
    }
   ],
   "source": [
    "pipe.apply_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings\n"
     ]
    }
   ],
   "source": [
    "pipe.create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(pipe.train_features[:130000], train[\"toxic\"][:130000])\n",
    "lgb_eval = lgb.Dataset(pipe.train_features[130000:], train[\"toxic\"][130000:], reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search\n",
      "Learning rate: 0.1 Number of leaves: 50\n",
      "[1]\tvalid_0's auc: 0.851814\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's auc: 0.884587\n",
      "[3]\tvalid_0's auc: 0.889251\n",
      "[4]\tvalid_0's auc: 0.893293\n",
      "[5]\tvalid_0's auc: 0.895416\n",
      "[6]\tvalid_0's auc: 0.900161\n",
      "[7]\tvalid_0's auc: 0.903824\n",
      "[8]\tvalid_0's auc: 0.905876\n",
      "[9]\tvalid_0's auc: 0.910826\n",
      "[10]\tvalid_0's auc: 0.915669\n",
      "[11]\tvalid_0's auc: 0.917323\n",
      "[12]\tvalid_0's auc: 0.918783\n",
      "[13]\tvalid_0's auc: 0.920056\n",
      "[14]\tvalid_0's auc: 0.921344\n",
      "[15]\tvalid_0's auc: 0.922308\n",
      "[16]\tvalid_0's auc: 0.924224\n",
      "[17]\tvalid_0's auc: 0.925308\n",
      "[18]\tvalid_0's auc: 0.927062\n",
      "[19]\tvalid_0's auc: 0.928703\n",
      "[20]\tvalid_0's auc: 0.929459\n",
      "[21]\tvalid_0's auc: 0.93071\n",
      "[22]\tvalid_0's auc: 0.931601\n",
      "[23]\tvalid_0's auc: 0.932446\n",
      "[24]\tvalid_0's auc: 0.933201\n",
      "[25]\tvalid_0's auc: 0.934619\n",
      "[26]\tvalid_0's auc: 0.936215\n",
      "[27]\tvalid_0's auc: 0.937074\n",
      "[28]\tvalid_0's auc: 0.938123\n",
      "[29]\tvalid_0's auc: 0.939621\n",
      "[30]\tvalid_0's auc: 0.940724\n",
      "[31]\tvalid_0's auc: 0.941846\n",
      "[32]\tvalid_0's auc: 0.942922\n",
      "[33]\tvalid_0's auc: 0.943379\n",
      "[34]\tvalid_0's auc: 0.944214\n",
      "[35]\tvalid_0's auc: 0.944997\n",
      "[36]\tvalid_0's auc: 0.945828\n",
      "[37]\tvalid_0's auc: 0.946398\n",
      "[38]\tvalid_0's auc: 0.946959\n",
      "[39]\tvalid_0's auc: 0.947534\n",
      "[40]\tvalid_0's auc: 0.948374\n",
      "[41]\tvalid_0's auc: 0.949026\n",
      "[42]\tvalid_0's auc: 0.949524\n",
      "[43]\tvalid_0's auc: 0.950276\n",
      "[44]\tvalid_0's auc: 0.950729\n",
      "[45]\tvalid_0's auc: 0.951282\n",
      "[46]\tvalid_0's auc: 0.951823\n",
      "[47]\tvalid_0's auc: 0.952197\n",
      "[48]\tvalid_0's auc: 0.952941\n",
      "[49]\tvalid_0's auc: 0.953649\n",
      "[50]\tvalid_0's auc: 0.954172\n",
      "[51]\tvalid_0's auc: 0.954676\n",
      "[52]\tvalid_0's auc: 0.955022\n",
      "[53]\tvalid_0's auc: 0.955401\n",
      "[54]\tvalid_0's auc: 0.955772\n",
      "[55]\tvalid_0's auc: 0.956141\n",
      "[56]\tvalid_0's auc: 0.956557\n",
      "[57]\tvalid_0's auc: 0.957022\n",
      "[58]\tvalid_0's auc: 0.957284\n",
      "[59]\tvalid_0's auc: 0.957683\n",
      "[60]\tvalid_0's auc: 0.957928\n",
      "[61]\tvalid_0's auc: 0.958223\n",
      "[62]\tvalid_0's auc: 0.958477\n",
      "[63]\tvalid_0's auc: 0.958763\n",
      "[64]\tvalid_0's auc: 0.959105\n",
      "[65]\tvalid_0's auc: 0.959351\n",
      "[66]\tvalid_0's auc: 0.959577\n",
      "[67]\tvalid_0's auc: 0.959842\n",
      "[68]\tvalid_0's auc: 0.960084\n",
      "[69]\tvalid_0's auc: 0.960442\n",
      "[70]\tvalid_0's auc: 0.960741\n",
      "[71]\tvalid_0's auc: 0.961083\n",
      "[72]\tvalid_0's auc: 0.961285\n",
      "[73]\tvalid_0's auc: 0.961488\n",
      "[74]\tvalid_0's auc: 0.961694\n",
      "[75]\tvalid_0's auc: 0.96191\n",
      "[76]\tvalid_0's auc: 0.962032\n",
      "[77]\tvalid_0's auc: 0.962265\n",
      "[78]\tvalid_0's auc: 0.962536\n",
      "[79]\tvalid_0's auc: 0.962702\n",
      "[80]\tvalid_0's auc: 0.962882\n",
      "[81]\tvalid_0's auc: 0.963034\n",
      "[82]\tvalid_0's auc: 0.963205\n",
      "[83]\tvalid_0's auc: 0.963397\n",
      "[84]\tvalid_0's auc: 0.963525\n",
      "[85]\tvalid_0's auc: 0.963557\n",
      "[86]\tvalid_0's auc: 0.963651\n",
      "[87]\tvalid_0's auc: 0.963801\n",
      "[88]\tvalid_0's auc: 0.963926\n",
      "[89]\tvalid_0's auc: 0.963962\n",
      "[90]\tvalid_0's auc: 0.96412\n",
      "[91]\tvalid_0's auc: 0.964279\n",
      "[92]\tvalid_0's auc: 0.96443\n",
      "[93]\tvalid_0's auc: 0.964514\n",
      "[94]\tvalid_0's auc: 0.964661\n",
      "[95]\tvalid_0's auc: 0.964792\n",
      "[96]\tvalid_0's auc: 0.964929\n",
      "[97]\tvalid_0's auc: 0.965067\n",
      "[98]\tvalid_0's auc: 0.965135\n",
      "[99]\tvalid_0's auc: 0.965259\n",
      "[100]\tvalid_0's auc: 0.965358\n",
      "[101]\tvalid_0's auc: 0.965516\n",
      "[102]\tvalid_0's auc: 0.965584\n",
      "[103]\tvalid_0's auc: 0.965655\n",
      "[104]\tvalid_0's auc: 0.965755\n",
      "[105]\tvalid_0's auc: 0.965883\n",
      "[106]\tvalid_0's auc: 0.96591\n",
      "[107]\tvalid_0's auc: 0.965927\n",
      "[108]\tvalid_0's auc: 0.966022\n",
      "[109]\tvalid_0's auc: 0.966141\n",
      "[110]\tvalid_0's auc: 0.966255\n",
      "[111]\tvalid_0's auc: 0.966286\n",
      "[112]\tvalid_0's auc: 0.966353\n",
      "[113]\tvalid_0's auc: 0.966415\n",
      "[114]\tvalid_0's auc: 0.966501\n",
      "[115]\tvalid_0's auc: 0.966621\n",
      "[116]\tvalid_0's auc: 0.966646\n",
      "[117]\tvalid_0's auc: 0.966722\n",
      "[118]\tvalid_0's auc: 0.966763\n",
      "[119]\tvalid_0's auc: 0.96681\n",
      "[120]\tvalid_0's auc: 0.966838\n",
      "[121]\tvalid_0's auc: 0.966963\n",
      "[122]\tvalid_0's auc: 0.967034\n",
      "[123]\tvalid_0's auc: 0.967057\n",
      "[124]\tvalid_0's auc: 0.967193\n",
      "[125]\tvalid_0's auc: 0.967296\n",
      "[126]\tvalid_0's auc: 0.967319\n",
      "[127]\tvalid_0's auc: 0.967319\n",
      "[128]\tvalid_0's auc: 0.967341\n",
      "[129]\tvalid_0's auc: 0.967406\n",
      "[130]\tvalid_0's auc: 0.967489\n",
      "[131]\tvalid_0's auc: 0.967511\n",
      "[132]\tvalid_0's auc: 0.967554\n",
      "[133]\tvalid_0's auc: 0.967548\n",
      "[134]\tvalid_0's auc: 0.967604\n",
      "[135]\tvalid_0's auc: 0.967553\n",
      "[136]\tvalid_0's auc: 0.967628\n",
      "[137]\tvalid_0's auc: 0.967662\n",
      "[138]\tvalid_0's auc: 0.9677\n",
      "[139]\tvalid_0's auc: 0.967827\n",
      "[140]\tvalid_0's auc: 0.967859\n",
      "[141]\tvalid_0's auc: 0.9679\n",
      "[142]\tvalid_0's auc: 0.967904\n",
      "[143]\tvalid_0's auc: 0.967952\n",
      "[144]\tvalid_0's auc: 0.967942\n",
      "[145]\tvalid_0's auc: 0.967952\n",
      "[146]\tvalid_0's auc: 0.967951\n",
      "[147]\tvalid_0's auc: 0.968011\n",
      "[148]\tvalid_0's auc: 0.968062\n",
      "[149]\tvalid_0's auc: 0.968091\n",
      "[150]\tvalid_0's auc: 0.968117\n",
      "[151]\tvalid_0's auc: 0.968181\n",
      "[152]\tvalid_0's auc: 0.968225\n",
      "[153]\tvalid_0's auc: 0.968282\n",
      "[154]\tvalid_0's auc: 0.968351\n",
      "[155]\tvalid_0's auc: 0.968346\n",
      "[156]\tvalid_0's auc: 0.968393\n",
      "[157]\tvalid_0's auc: 0.968363\n",
      "[158]\tvalid_0's auc: 0.968394\n",
      "[159]\tvalid_0's auc: 0.968424\n",
      "[160]\tvalid_0's auc: 0.968453\n",
      "[161]\tvalid_0's auc: 0.968444\n",
      "[162]\tvalid_0's auc: 0.968468\n",
      "[163]\tvalid_0's auc: 0.968491\n",
      "[164]\tvalid_0's auc: 0.9685\n",
      "[165]\tvalid_0's auc: 0.96858\n",
      "[166]\tvalid_0's auc: 0.968567\n",
      "[167]\tvalid_0's auc: 0.968622\n",
      "[168]\tvalid_0's auc: 0.968657\n",
      "[169]\tvalid_0's auc: 0.968694\n",
      "[170]\tvalid_0's auc: 0.968675\n",
      "[171]\tvalid_0's auc: 0.968728\n",
      "[172]\tvalid_0's auc: 0.968734\n",
      "[173]\tvalid_0's auc: 0.968754\n",
      "[174]\tvalid_0's auc: 0.968783\n",
      "[175]\tvalid_0's auc: 0.968853\n",
      "[176]\tvalid_0's auc: 0.968841\n",
      "[177]\tvalid_0's auc: 0.968819\n",
      "[178]\tvalid_0's auc: 0.96885\n",
      "[179]\tvalid_0's auc: 0.968924\n",
      "[180]\tvalid_0's auc: 0.968965\n",
      "[181]\tvalid_0's auc: 0.968971\n",
      "[182]\tvalid_0's auc: 0.969012\n",
      "[183]\tvalid_0's auc: 0.969022\n",
      "[184]\tvalid_0's auc: 0.968986\n",
      "[185]\tvalid_0's auc: 0.968987\n",
      "[186]\tvalid_0's auc: 0.968943\n",
      "[187]\tvalid_0's auc: 0.968967\n",
      "[188]\tvalid_0's auc: 0.968945\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's auc: 0.969022\n",
      "defaultdict(<class 'dict'>, {'valid_0': {'auc': 0.9690220841884837}})\n",
      "Learning rate: 0.2 Number of leaves: 50\n",
      "[1]\tvalid_0's auc: 0.851814\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's auc: 0.884808\n",
      "[3]\tvalid_0's auc: 0.895876\n",
      "[4]\tvalid_0's auc: 0.901219\n",
      "[5]\tvalid_0's auc: 0.904674\n",
      "[6]\tvalid_0's auc: 0.911484\n",
      "[7]\tvalid_0's auc: 0.913993\n",
      "[8]\tvalid_0's auc: 0.919561\n",
      "[9]\tvalid_0's auc: 0.923426\n",
      "[10]\tvalid_0's auc: 0.926515\n",
      "[11]\tvalid_0's auc: 0.929168\n",
      "[12]\tvalid_0's auc: 0.932179\n",
      "[13]\tvalid_0's auc: 0.933866\n",
      "[14]\tvalid_0's auc: 0.934746\n",
      "[15]\tvalid_0's auc: 0.937475\n",
      "[16]\tvalid_0's auc: 0.939531\n",
      "[17]\tvalid_0's auc: 0.941637\n",
      "[18]\tvalid_0's auc: 0.943887\n",
      "[19]\tvalid_0's auc: 0.945209\n",
      "[20]\tvalid_0's auc: 0.946618\n",
      "[21]\tvalid_0's auc: 0.947863\n",
      "[22]\tvalid_0's auc: 0.948644\n",
      "[23]\tvalid_0's auc: 0.94959\n",
      "[24]\tvalid_0's auc: 0.950794\n",
      "[25]\tvalid_0's auc: 0.951379\n",
      "[26]\tvalid_0's auc: 0.952002\n",
      "[27]\tvalid_0's auc: 0.952632\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-7c7df3e77ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlgb_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             early_stopping_rounds=5)\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting grid search\")\n",
    "for lr in [0.1,0.2]:\n",
    "    print(\"Learning rate:\", lr, \"Number of leaves:\", nl)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': lr,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'reg_lambda': 0.5\n",
    "    }\n",
    "    gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=200,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=5)\n",
    "    print(gbm.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'lambda': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier(metric=\"auc\", num_leaves=31, boosting_type=\"gbdt\", learning_rate=0.1, feature_fraction=0.9, bagging_fraction=0.8, bagging_freq=5, reg_lambda=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "Fit\n",
      "Predict\n",
      "severe_toxic\n",
      "Fit\n",
      "Predict\n",
      "obscene\n",
      "Fit\n",
      "Predict\n",
      "threat\n",
      "Fit\n",
      "Predict\n",
      "insult\n",
      "Fit\n",
      "Predict\n",
      "identity_hate\n",
      "Fit\n",
      "Predict\n"
     ]
    }
   ],
   "source": [
    "for label in pipe.class_labels:\n",
    "    print(label)\n",
    "    print(\"Fit\")\n",
    "    gbm.fit(pipe.train_features, train[label])\n",
    "    print(\"Predict\")\n",
    "    pipe.predictions[label] = gbm.predict_proba(pipe.test_features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic regression newton': -1}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.cv_scores[\"LightGBM\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LightGBM'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.models[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pipe.test[pipe.id_column].to_frame()\n",
    "for label in pipe.class_labels:\n",
    "    submission[label] = pipe.predictions[label]\n",
    "\n",
    "filename = 'submissions\\\\submission23.csv'\n",
    "submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identity_hate': array([9.55569199e-01, 2.39053048e-04, 1.78022777e-03, ...,\n",
       "        3.31452501e-04, 2.11595090e-03, 4.51964093e-03]),\n",
       " 'insult': array([0.94767719, 0.00432006, 0.01133886, ..., 0.00166285, 0.00209999,\n",
       "        0.29476007]),\n",
       " 'obscene': array([0.99431291, 0.00482181, 0.01335664, ..., 0.00308492, 0.00266341,\n",
       "        0.22345165]),\n",
       " 'severe_toxic': array([2.34768439e-01, 2.08802172e-04, 7.07685689e-03, ...,\n",
       "        1.78179018e-04, 6.10784256e-04, 3.50254694e-03]),\n",
       " 'threat': array([1.83904419e-01, 1.41904852e-04, 2.89499988e-04, ...,\n",
       "        5.48113233e-05, 1.98012367e-04, 2.79884538e-04]),\n",
       " 'toxic': array([0.99600831, 0.00662445, 0.03037946, ..., 0.00592981, 0.00517886,\n",
       "        0.73509946])}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999996"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_train = train[\"comment_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_test = test[\"comment_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list_sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([list_sentences_train, list_sentences_test]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     1      5     10 ... 159554 159557 159565]\n",
      "[     6      8      9 ... 159547 159549 159559]\n",
      "[     3     15     17 ... 159545 159552 159560]\n",
      "[     2     11     18 ... 159563 159567 159568]\n",
      "[     0      4      7 ... 159566 159569 159570]\n"
     ]
    }
   ],
   "source": [
    "for fold, fold2 in folds.split(train[\"id\"]):\n",
    "    print(fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [idx for idx in folds.split(train[\"id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(fold):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "    indices = [idx for idx in folds.split(train[\"id\"])]\n",
    "    train_idx = indices[fold][0]\n",
    "    pred_idx = indices[fold][1]\n",
    "    return train_idx, pred_idx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, pred_idx = get_indices(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing\n"
     ]
    }
   ],
   "source": [
    "embed_size = 300\n",
    "max_features = 394787\n",
    "maxlen = 100\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].values\n",
    "\n",
    "print(\"Tokenizing\")\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(np.concatenate([list_sentences_train, list_sentences_test])))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmNet2():\n",
    "    \n",
    "    def __init__(self, embed_size, max_features, maxlen, embedding_matrix):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "        x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(50, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(6, activation=\"sigmoid\")(x)\n",
    "        self.model = Model(inputs=inp, outputs=x)\n",
    "        # optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, train_features, train_labels):\n",
    "        early = [callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=0, verbose=0, mode='auto')]\n",
    "        self.model.fit(train_features, train_labels, batch_size=32, epochs=2, callbacks=early)\n",
    "\n",
    "    def predict_proba(self, features):\n",
    "        self.predictions = self.model.predict([features], batch_size=1024, verbose=1)\n",
    "        return self.predictions\n",
    "\n",
    "    def submit(self):\n",
    "        sub = pd.read_csv('data\\\\sample_submission.csv')\n",
    "        sub[list_classes] = self.predictions\n",
    "        sub.to_csv('submissions\\\\lstm5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "train_idx, pred_idx = get_indices(fold)\n",
    "net = LstmNet2(embed_size, max_features, maxlen, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:94: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 118436100 elements. This may consume a large amount of memory.\n",
      "  \"This may consume a large amount of memory.\" % num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[394787,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_11/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/acc/Mean_1/_335 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4629_metrics_1/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_1/Adam/mul_3', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-286-7f674e174aaa>\", line 1, in <module>\n    net.fit(X_t[train_idx], y[train_idx])\n  File \"<ipython-input-282-133755313139>\", line 17, in fit\n    self.model.fit(train_features, train_labels, batch_size=32, epochs=2, callbacks=early)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1646, in fit\n    self._make_train_function()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 456, in get_updates\n    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 775, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 907, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3100, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[394787,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_11/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/acc/Mean_1/_335 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4629_metrics_1/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[394787,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_11/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/acc/Mean_1/_335 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4629_metrics_1/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-7f674e174aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-282-133755313139>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_features, train_labels)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mearly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[394787,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_11/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/acc/Mean_1/_335 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4629_metrics_1/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_1/Adam/mul_3', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-286-7f674e174aaa>\", line 1, in <module>\n    net.fit(X_t[train_idx], y[train_idx])\n  File \"<ipython-input-282-133755313139>\", line 17, in fit\n    self.model.fit(train_features, train_labels, batch_size=32, epochs=2, callbacks=early)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1646, in fit\n    self._make_train_function()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 456, in get_updates\n    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 775, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 907, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3100, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[394787,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_11/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_1/acc/Mean_1/_335 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4629_metrics_1/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "net.fit(X_t[train_idx], y[train_idx])\n",
    "y_test = net.predict_proba(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_oof = pd.read_csv('data\\\\sample_submission.csv')\n",
    "sub_oof[list_classes] = y_test\n",
    "sub_oof.to_csv('submission\\\\lstm_ft_oof' + fold + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-288-c2296bf96d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
