{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nlp_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained = \"data\\\\crawl-300d-2M.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = get_pretrained(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data\\\\train.csv\").fillna(' ')\n",
    "test = pd.read_csv(\"data\\\\test.csv\").fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "def tokenize(row):\n",
    "    return re_tok.sub(r' \\1 ', row).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = [column for column in train.columns[2:8]]\n",
    "feature_funcs = [len, asterix_freq, uppercase_freq, line_change_freq, rep_freq, question_freq]\n",
    "transforms = [tokenize]\n",
    "gbm = lgb.LGBMClassifier(max_depth=3, metric=\"auc\", num_leaves=20, boosting_type=\"gbdt\", learning_rate=0.1, feature_fraction=0.9, bagging_fraction=0.8, bagging_freq=5, reg_lambda=0.2)\n",
    "gbm.name = \"LightGBM\"\n",
    "models = [gbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (159571, 8)\n",
      "Test: (153164, 2)\n",
      "Train features: (0,)\n",
      "Test features: (0,)\n",
      "Input column: comment_text\n",
      "Class labels: toxic severe_toxic obscene threat insult identity_hate\n",
      "Models: LightGBM: gbdt None 1.0 0.1 3 20 0.001 0.0 100 -1 20 None None 0.0 0.2 True 1.0 200000 1 auc 0.9 0.8 5 | \n",
      "Transforms:  tokenize\n",
      "Feature functions:  function asterix_freq uppercase_freq line_change_freq rep_freq question_freq\n",
      "Metric: roc_auc\n",
      "CV scores: {'LightGBM': -1}\n"
     ]
    }
   ],
   "source": [
    "pipe = NlpPipeline(train, test, \"comment_text\", class_labels, feature_funcs, transforms, models, word_index=word_vector, pretrained=pretrained)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features\n"
     ]
    }
   ],
   "source": [
    "pipe.engineer_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transforms\n"
     ]
    }
   ],
   "source": [
    "pipe.apply_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings\n"
     ]
    }
   ],
   "source": [
    "pipe.create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'num_leaves': [10, 15, 20], \n",
    "   'max_depth': [2,3,5],\n",
    "   'learning_rate': [0.08,0.1,0.12]}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',\n",
       "        class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,\n",
       "        learning_rate=0.1, max_depth=3, metric='auc', min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=20, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.2, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'num_leaves': [10, 15, 20], 'max_depth': [2, 3, 5], 'learning_rate': [0.08, 0.1, 0.12]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(gbm, param_grid)\n",
    "clf.fit(pipe.train_features, train[\"severe_toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 10}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating\n",
      "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',\n",
      "        class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,\n",
      "        learning_rate=0.1, max_depth=3, metric='auc', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=10, objective=None, random_state=None,\n",
      "        reg_alpha=0.0, reg_lambda=0.2, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=1)\n",
      "Cross-validating toxic\n",
      "roc_auc: 0.95795622029\n",
      "Cross-validating severe_toxic\n",
      "roc_auc: 0.983969351099\n",
      "Cross-validating obscene\n",
      "roc_auc: 0.971628670957\n",
      "Cross-validating threat\n",
      "roc_auc: 0.974643685149\n",
      "Cross-validating insult\n",
      "roc_auc: 0.969079826691\n",
      "Cross-validating identity_hate\n",
      "roc_auc: 0.974837895119\n"
     ]
    }
   ],
   "source": [
    "pipe.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating out-of-fold meta training set for stacker\n",
      "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',\n",
      "        class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,\n",
      "        learning_rate=0.1, max_depth=3, metric='auc', min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=10, objective=None, random_state=None,\n",
      "        reg_alpha=0.0, reg_lambda=0.2, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=1)\n",
      "toxic\n",
      "AUC: 0.956549533623\n",
      "AUC: 0.957561008854\n",
      "AUC: 0.960646629136\n",
      "AUC: 0.9567841933\n",
      "AUC: 0.958794141654\n",
      "severe_toxic\n",
      "AUC: 0.983588656074\n",
      "AUC: 0.984221508909\n",
      "AUC: 0.983461670074\n",
      "AUC: 0.985227479713\n",
      "AUC: 0.984391548349\n",
      "obscene\n",
      "AUC: 0.970237136293\n",
      "AUC: 0.971839531338\n",
      "AUC: 0.975834772677\n",
      "AUC: 0.9707452455\n",
      "AUC: 0.970833380932\n",
      "threat\n",
      "AUC: 0.97918670217\n",
      "AUC: 0.970884365001\n",
      "AUC: 0.969385609206\n",
      "AUC: 0.977309996698\n",
      "AUC: 0.970492082159\n",
      "insult\n",
      "AUC: 0.967139970311\n",
      "AUC: 0.968618007257\n",
      "AUC: 0.972309887679\n",
      "AUC: 0.96968191343\n",
      "AUC: 0.968294212951\n",
      "identity_hate\n",
      "AUC: 0.967896506821\n",
      "AUC: 0.97890619086\n",
      "AUC: 0.973925830293\n",
      "AUC: 0.972325347456\n",
      "AUC: 0.975760361852\n",
      "CV score: 0.971761114019\n",
      "Fitting and predicting\n",
      "Fitting submission classifier for toxic\n",
      "Fitting submission classifier for severe_toxic\n",
      "Fitting submission classifier for obscene\n",
      "Fitting submission classifier for threat\n",
      "Fitting submission classifier for insult\n",
      "Fitting submission classifier for identity_hate\n"
     ]
    }
   ],
   "source": [
    "pipe.fit_predict_oof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submissions\n"
     ]
    }
   ],
   "source": [
    "pipe.create_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
